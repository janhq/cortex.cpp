"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8741],{42524:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>p,frontMatter:()=>o,metadata:()=>r,toc:()=>c});var s=t(85893),a=t(11151);const o={title:"Vision",description:"Inference engine for vision, the same as OpenAI's",keywords:["Nitro","Jan","fast inference","inference server","local AI","large language model","OpenAI compatible","open source","llava","bakllava","vision"]},i=void 0,r={id:"features/vision",title:"Vision",description:"Inference engine for vision, the same as OpenAI's",source:"@site/docs/features/vision.md",sourceDirName:"features",slug:"/features/vision",permalink:"/features/vision",draft:!1,unlisted:!1,editUrl:"https://github.com/janhq/nitro/tree/main/docs/docs/features/vision.md",tags:[],version:"current",lastUpdatedBy:"automaticcat",lastUpdatedAt:1712102252,formattedLastUpdatedAt:"Apr 2, 2024",frontMatter:{title:"Vision",description:"Inference engine for vision, the same as OpenAI's",keywords:["Nitro","Jan","fast inference","inference server","local AI","large language model","OpenAI compatible","open source","llava","bakllava","vision"]},sidebar:"docsSidebar",previous:{title:"Embedding",permalink:"/features/embed"},next:{title:"Nitro Features",permalink:"/features/feat"}},l={},c=[{value:"Load model",id:"load-model",level:2},{value:"Inference",id:"inference",level:2}];function d(e){const n={a:"a",code:"code",h2:"h2",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h2,{id:"load-model",children:"Load model"}),"\n",(0,s.jsx)(n.p,{children:"Just like loading the Chat model, for the vision model, you need two specific types:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["the ",(0,s.jsx)(n.code,{children:"GGUF model"})]}),"\n",(0,s.jsxs)(n.li,{children:["the ",(0,s.jsx)(n.code,{children:"mmproj model"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"You can load the model using:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",metastring:'title="Load Model" {3,4}',children:'curl -X POST \'http://127.0.0.1:3928/inferences/llamacpp/loadmodel\' -H \'Content-Type: application/json\' -d \'{\n   "llama_model_path": "/path/to/gguf/model/",\n   "mmproj": "/path/to/mmproj/model/",\n   "ctx_len": 2048,\n   "ngl": 100,\n   "cont_batching": false,\n   "embedding": false,\n   "system_prompt": "",\n   "user_prompt": "\\n### Instruction:\\n",\n   "ai_prompt": "\\n### Response:\\n"\n }\'\n'})}),"\n",(0,s.jsx)(n.p,{children:"Download the models here:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"https://huggingface.co/jartine/llava-v1.5-7B-GGUF/tree/main",children:"Llava Model"}),": Large Language and Vision Assistant achieves SoTA on 11 benchmarks."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"https://huggingface.co/mys/ggml_bakllava-1/tree/main",children:"Bakllava Model"})," is a Mistral 7B base augmented with the LLaVA architecture."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"inference",children:"Inference"}),"\n",(0,s.jsxs)(n.p,{children:["Nitro currently only works with images converted to base64 format. Use this ",(0,s.jsx)(n.a,{href:"https://www.base64-image.de/",children:"base64 converter"})," to prepare your images."]}),"\n",(0,s.jsx)(n.p,{children:"To get the model's understanding of an image, do the following:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",metastring:'title="Inference"',children:'curl http://127.0.0.1:3928/v1/chat/completions \\\n  -H "Content-Type: application/json" \\\n  -H "Authorization: Bearer $OPENAI_API_KEY" \\\n  -d \'{\n    "model": "gpt-4-vision-preview",\n    "messages": [\n      {\n        "role": "user",\n        "content": [\n          {\n            "type": "text",\n            "text": "What\u2019s in this image?"\n          },\n          {\n            "type": "image_url",\n            "image_url": {\n              "url": "<base64>"\n            }\n          }\n        ]\n      }\n    ],\n    "max_tokens": 300\n  }\'\n'})}),"\n",(0,s.jsxs)(n.p,{children:["If the base64 string is too long and causes errors, consider using ",(0,s.jsx)(n.a,{href:"https://www.postman.com/",children:"Postman"})," as an alternative."]})]})}function p(e={}){const{wrapper:n}={...(0,a.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},11151:(e,n,t)=>{t.d(n,{Z:()=>r,a:()=>i});var s=t(67294);const a={},o=s.createContext(a);function i(e){const n=s.useContext(o);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);